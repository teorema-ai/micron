{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ad5528-1e2f-4282-a5d1-66a62ab13f1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab83372c-17d6-4f86-9c87-6003a13bc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0bc518-69bb-433d-8cd9-e6f6de612594",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, 'data')\n",
    "MIRNA_DATA_PATH = os.path.join(DATA_PATH, 'mirna.tsv')\n",
    "MIRNA_MODEL_NAME = \"mirna\"\n",
    "MIRNA_MODEL_VERSION = \"0\"\n",
    "MIRNA_MODEL_CHECKPOINT = \"checkpoint-1000\"\n",
    "MIRNA_MODEL_ROOT = os.path.join(os.getcwd(), f\"model={MIRNA_MODEL_NAME}\", f\"version={MIRNA_MODEL_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ece5fd5-4792-4a52-9178-de0d1561cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MIRNA_MODEL_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861cac1a-406a-4226-8e79-bfdfdb5faaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/data/home/dkarpeyev/micron/data/mirna.tsv',\n",
       " '/mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIRNA_DATA_PATH, MIRNA_MODEL_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3570b-3fb2-4d9e-b0f5-6b09274dea43",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd05f736-f89f-4a26-aa4f-425bfb959740",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_str = open(MIRNA_DATA_PATH).read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf981cb-d1cb-4d2c-8b20-027ccd0c1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_list = re.split(' |\\n', mirna_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e175ca2-1996-4a42-b755-83880cdbe543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5751"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mirna_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92fb9ec-8733-4fc9-abb0-5333a83f707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-let-7a-1',\n",
       " 'MI0000060',\n",
       " 'UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA',\n",
       " '>hsa-let-7a-2',\n",
       " 'MI0000061',\n",
       " 'AGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGAUAACUGUACAGCCUCCUAGCUUUCCU',\n",
       " '>hsa-let-7a-3',\n",
       " 'MI0000062',\n",
       " 'GGGUGAGGUAGUAGGUUGUAUAGUUUGGGGCUCUGCCCUGCUAUGGGAUAACUAUACAAUCUACUGUCUUUCCU']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirna_list[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de38aad-538a-4f9d-9463-18549ccd8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>hsa-mir-12135',\n",
       " 'MI0039739',\n",
       " 'UGUGGAUAUUCUUUUUUGAUACUACAGCAAAACUCAGCAAGUUGUAGUUUUUUAAAGGUUUGUUUGUAAA',\n",
       " '>hsa-mir-12136',\n",
       " 'MI0039740',\n",
       " 'GAAAAAGUCAUGGAGGCCAUGGGGUUGGCUUGAAACCAGCUUUGGGGGGUUCGAUUCCUUCCUUUUUUGUC',\n",
       " '>hsa-mir-9902-2',\n",
       " 'MI0041071',\n",
       " 'GCAGGGAAAGGGAACCCAGAAAUCUGGUAUGCCAGCAAAGAGAGUAAGAACUUCUGACAAGCCAGGCUUCUGGUCUCUCUCUCUCUGUCUCUC']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirna_list[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311f7954-ee1f-4854-a012-2b24e1722d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_array_1 = np.array(mirna_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d572750c-7642-451a-98c5-918ec707f292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5751,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirna_array_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e032b780-238d-4b5d-94a9-7c40f7c8e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_array_2 = mirna_array_1.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8583b788-27cf-4020-8757-273239b4eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = pd.DataFrame.from_records(mirna_array_2, columns=['ID', 'Accession', 'sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9a5a83-c40c-4bc7-a440-2c2413e960b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma['ID'] = ma['ID'].map(lambda _: _[1:] if _.startswith('>') else _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2555d59-08aa-43f3-ab05-c2152a14df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Accession</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a-let-7a-1</td>\n",
       "      <td>MI0000060</td>\n",
       "      <td>UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hsa-let-7a-2</td>\n",
       "      <td>MI0000061</td>\n",
       "      <td>AGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hsa-let-7a-3</td>\n",
       "      <td>MI0000062</td>\n",
       "      <td>GGGUGAGGUAGUAGGUUGUAUAGUUUGGGGCUCUGCCCUGCUAUGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hsa-let-7b</td>\n",
       "      <td>MI0000063</td>\n",
       "      <td>CGGGGUGAGGUAGUAGGUUGUGUGGUUUCAGGGCAGUGAUGUUGCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hsa-let-7c</td>\n",
       "      <td>MI0000064</td>\n",
       "      <td>GCAUCCGGGUUGAGGUAGUAGGUUGUAUGGUUUAGAGUUACACCCU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>hsa-mir-12132</td>\n",
       "      <td>MI0039734</td>\n",
       "      <td>UUAACAUCUUUUCCAUCAUAAUUCUCAUAGUAAUAAUAGUAAUGUU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>hsa-mir-12133</td>\n",
       "      <td>MI0039735</td>\n",
       "      <td>GAAGUGUACUUUUUAAUGGUGCCAAACAGCAGUUGAUCUAUAAUAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>hsa-mir-12135</td>\n",
       "      <td>MI0039739</td>\n",
       "      <td>UGUGGAUAUUCUUUUUUGAUACUACAGCAAAACUCAGCAAGUUGUA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>hsa-mir-12136</td>\n",
       "      <td>MI0039740</td>\n",
       "      <td>GAAAAAGUCAUGGAGGCCAUGGGGUUGGCUUGAAACCAGCUUUGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>hsa-mir-9902-2</td>\n",
       "      <td>MI0041071</td>\n",
       "      <td>GCAGGGAAAGGGAACCCAGAAAUCUGGUAUGCCAGCAAAGAGAGUA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Accession  \\\n",
       "0         a-let-7a-1  MI0000060   \n",
       "1       hsa-let-7a-2  MI0000061   \n",
       "2       hsa-let-7a-3  MI0000062   \n",
       "3         hsa-let-7b  MI0000063   \n",
       "4         hsa-let-7c  MI0000064   \n",
       "...              ...        ...   \n",
       "1912   hsa-mir-12132  MI0039734   \n",
       "1913   hsa-mir-12133  MI0039735   \n",
       "1914   hsa-mir-12135  MI0039739   \n",
       "1915   hsa-mir-12136  MI0039740   \n",
       "1916  hsa-mir-9902-2  MI0041071   \n",
       "\n",
       "                                               sequence  \n",
       "0     UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCAC...  \n",
       "1     AGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGA...  \n",
       "2     GGGUGAGGUAGUAGGUUGUAUAGUUUGGGGCUCUGCCCUGCUAUGG...  \n",
       "3     CGGGGUGAGGUAGUAGGUUGUGUGGUUUCAGGGCAGUGAUGUUGCC...  \n",
       "4     GCAUCCGGGUUGAGGUAGUAGGUUGUAUGGUUUAGAGUUACACCCU...  \n",
       "...                                                 ...  \n",
       "1912  UUAACAUCUUUUCCAUCAUAAUUCUCAUAGUAAUAAUAGUAAUGUU...  \n",
       "1913  GAAGUGUACUUUUUAAUGGUGCCAAACAGCAGUUGAUCUAUAAUAA...  \n",
       "1914  UGUGGAUAUUCUUUUUUGAUACUACAGCAAAACUCAGCAAGUUGUA...  \n",
       "1915  GAAAAAGUCAUGGAGGCCAUGGGGUUGGCUUGAAACCAGCUUUGGG...  \n",
       "1916  GCAGGGAAAGGGAACCCAGAAAUCUGGUAUGCCAGCAAAGAGAGUA...  \n",
       "\n",
       "[1917 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c5b0d66-c46d-419d-a3d3-5c8cefc7d0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'C', 'G', 'U'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda a, b: a.union(set(b)), ma.sequence, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d632141-8e30-4504-b478-eb9208babfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'C', 'G', 'U'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ma.iloc[0].sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984161c1-7c31-4d25-8858-35ced6055cf0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "672fd4d4-ea79-44bb-977f-ab9877c109b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN_FRACTION = 9/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe274916-485b-4752-8711-969a9fcbf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "825dd0a3-6627-4040-b42d-d83ab65ae287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e085e87b-eb0a-47bc-9e9b-8b4b932cb4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dataset.from_generator?\n",
    "mirna_train_dataset = Dataset.from_pandas(ma.iloc[:int(DATASET_TRAIN_FRACTION*len(ma))], split='train')\n",
    "mirna_test_dataset = Dataset.from_pandas(ma.iloc[int(DATASET_TRAIN_FRACTION*len(ma)):], split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d5596ae-dabb-4151-9a62-f6426dc8864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(mirna_train_dataset.data.table, pa.Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebb03f96-b4f0-4e8b-8fd1-e2a7cc2ed33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRNA_TRAIN_PATH = os.path.join(MIRNA_MODEL_ROOT, f\"{MIRNA_MODEL_NAME}_train.parquet\")\n",
    "pq.write_table(mirna_train_dataset.data.table, MIRNA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e24fb435-6a0b-4bb9-8e73-2c564a1f4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRNA_TEST_PATH = os.path.join(MIRNA_MODEL_ROOT, f\"{MIRNA_MODEL_NAME}_test.parquet\")\n",
    "pq.write_table(mirna_test_dataset.data.table, MIRNA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "569c5583-4f41-4255-b5b0-4966bd0793e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": mirna_train_dataset,  # .shuffle().select(range(50000)),\n",
    "        \"test\": mirna_test_dataset,  # .shuffle().select(range(500))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fef3c899-6b85-451b-9d71-865beb0fd62e",
   "metadata": {},
   "source": [
    "mirna_dataset_dict = load_dataset(\"parquet\", \n",
    "                                  data_files={splits.Split.TRAIN: MIRNA_TRAIN_PATH, splits.Split.TEST: MIRNA_TEST_PATH},)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f1688b-f1cd-46a9-af4b-74e52c148d0c",
   "metadata": {},
   "source": [
    "mirna_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41806611-0bda-471e-a8e5-b4cc2263de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sequence0 = ma.iloc[0].sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "effe401e-1489-409d-a39d-0520219fe9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIRNA_MAX_SEQUENCE_LENGTH = max(max(len(tt) for tt in ds['sequence']) for ds in mirna_datasets.values())\n",
    "MIRNA_MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d7206-907c-49d9-bc02-85f3fe5902db",
   "metadata": {},
   "source": [
    "# TOKENIZER\n",
    "\n",
    "Building following tutorial: https://huggingface.co/course/chapter6/8?fw=pt\n",
    "\n",
    "Specifically, 'GPT-2' BPE-based Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed4e97e2-25de-48a8-b827-010bb05f50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def get_tokenizer_training_corpus(dataset_dict, *, chunk_size):\n",
    "    dd = dataset_dict\n",
    "    sequence_list = reduce(lambda sequence, ds: sequence+ds['sequence'], dd.values(), [])\n",
    "    for i in range(0, len(sequence_list), chunk_size):\n",
    "        yield sequence_list[i:i+chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e303553-c356-48c8-87fd-e37695c5ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62f7a8fb-df27-4706-99cb-b4485063805e",
   "metadata": {},
   "source": [
    "#_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\", bos_token=\"[BOS]\", eos_token=\"[EOS]\"))\n",
    "_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c2ddc77-aa12-48f3-ad03-07c623b69de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = Tokenizer(models.BPE()) # all tokens are known"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e4f3b61-8907-4728-ae04-c35722add884",
   "metadata": {},
   "source": [
    "# No normalization is necessary\n",
    "_tokenizer.normalizer = normalizers.Sequence(\n",
    "    [#normalizers.NFD(), \n",
    "     normalizers.Lowercase(), \n",
    "     normalizers.StripAccents()]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d0c8598-3a6a-4875-92e3-c30280ddb0c5",
   "metadata": {},
   "source": [
    "_tokenizer.normalizer.normalize_str(_sequence0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e78479b9-4ee8-41fc-bcc6-b74785bd4d11",
   "metadata": {},
   "source": [
    "_tokenizer.pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aedea761-0db2-4429-b0c9-771945806665",
   "metadata": {},
   "source": [
    "_tokenizer.pre_tokenizer.pre_tokenize_str(_tokenizer.normalizer.normalize_str(_sequence0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecf37eea-f99d-46fd-bdfb-9fce7f3a5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44203d0e-fb88-4fa9-a8f3-86af5c3d8718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA',\n",
       "  (0, 80))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tokenizer.pre_tokenizer.pre_tokenize_str(_sequence0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7d4c105-2c9e-4121-a1b1-de2fbd972002",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_TRAINER_CHUNK_SIZE = 200\n",
    "VOCAB_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "379e681d-e3c4-4a4d-a42d-0eabb096fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"<|endoftext|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12c49813-b2f9-4713-8c91-4632c7f156a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_tokenizer.train_from_iterator(get_tokenizer_training_corpus(mirna_datasets, chunk_size=TOKENIZER_TRAINER_CHUNK_SIZE), \n",
    "                              trainer=tokenizer_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25f72365-5b20-4604-80d4-ffae929c39cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b239e12e-eecf-4e01-87d1-739eb5ca70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_encoding = _tokenizer.encode(_sequence0)\n",
    "_tokens = _encoding.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "710fe509-98e2-4a0e-ac3c-2f1ee53ead89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UGGG', 'AUG', 'AGG', 'UAG', 'UAGG', 'UUG', 'UA', 'UAG', 'UUUU', 'AGGG', 'UCAC', 'ACCC', 'ACC', 'AC', 'UGGG', 'AGA', 'UAAC', 'UA', 'UAC', 'AA', 'UC', 'UAC', 'UGUC', 'UU', 'UCC', 'UA']\n"
     ]
    }
   ],
   "source": [
    "print(_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e31b67c7-72e0-495f-8a1d-556b1c031ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94a755ca-cfbf-48e7-a1fd-3f5c5546ce51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UAGG'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_ = _tokenizer.encode(_sequence0)\n",
    "start, end = encoding_.offsets[4]\n",
    "_sequence0[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bcc1dd0-1fd5-4693-bb39-bbbc972cbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abe899cb-4aff-4303-93b9-1b5399072085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence0_ = _tokenizer.decode(_encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aab9de4a-9d15-459e-9f4f-e2607a614f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sequence0 == sequence0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db4ded74-36d1-446f-95a2-0ab76cbc620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PATH = os.path.join(MIRNA_MODEL_ROOT, f\"{MIRNA_MODEL_NAME}_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a30cfb6-5219-4e00-b90f-4f315b145b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer.save(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5acae7d-078e-4b1e-bf43-38f151d22230",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = Tokenizer.from_file(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf680e12-e1e5-4463-9458-6d7d03412d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=_tokenizer,\n",
    "    bos_token=\"<|endoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3224b175-c7c5-415a-919f-d9c890227189",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(_sequence0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6072322d-debf-43b1-8a11-bc4ec1e5a9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22,\n",
       " 29,\n",
       " 14,\n",
       " 30,\n",
       " 59,\n",
       " 20,\n",
       " 17,\n",
       " 30,\n",
       " 40,\n",
       " 25,\n",
       " 50,\n",
       " 56,\n",
       " 26,\n",
       " 12,\n",
       " 22,\n",
       " 27,\n",
       " 73,\n",
       " 17,\n",
       " 28,\n",
       " 9,\n",
       " 11,\n",
       " 28,\n",
       " 64,\n",
       " 8,\n",
       " 16,\n",
       " 17]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb3c9659-2099-475c-805e-8db36069b0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f2da50a-b13c-4f22-9b56-1411742db5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ef1660-a262-4974-90a5-2febacd2c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(mirna_datasets['train']['sequence'])['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2109ca6-aaff-4347-bd3f-c624d3da267a",
   "metadata": {},
   "source": [
    "## Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02bb1321-bb6c-43ad-934b-a7542d92908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIRNA_MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2802d33f-2bbb-491a-9385-5100081d93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRNA_CONTEXT_LENGTH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05ad042e-a371-414d-aa6d-31eeef742b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Accession', 'sequence'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Accession', 'sequence'],\n",
       "        num_rows: 192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirna_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27921acf-ab86-42e2-9513-932503ce7199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013243675231933594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca8d4e01b40415e8e8f31eaabebcc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012343168258666992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa8b385f79340cfa556df7ccc225423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'length', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'length', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(row, *, context_length=MIRNA_CONTEXT_LENGTH):\n",
    "    outputs = tokenizer(\n",
    "        row[\"sequence\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    return outputs\n",
    "    \"\"\"\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "mirna_tokenized_datasets = mirna_datasets.map(tokenize, batched=True, remove_columns=mirna_datasets[\"train\"].column_names)\n",
    "mirna_tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19858b6-840b-4b5f-a6fb-6ec0ce37ce9f",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "588c302c-2ff7-4d16-ada7-2e5bb2f519b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=MIRNA_CONTEXT_LENGTH,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00c23dd4-587e-4c89-b5f2-56d83eb80fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 85.9M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb89a46d-9d65-48bf-a1a9-449c48834051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae464b7-5873-49a9-81f4-79fe1ffe51a0",
   "metadata": {},
   "source": [
    "Let’s have a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4fa5282-2d36-4274-9221-51efe043da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 30])\n",
      "token_type_ids shape: torch.Size([5, 30])\n",
      "attention_mask shape: torch.Size([5, 30])\n",
      "length shape: torch.Size([5])\n",
      "overflow_to_sample_mapping shape: torch.Size([5])\n",
      "labels shape: torch.Size([5, 30])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([mirna_tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a76d8-90ed-4b38-88f6-115204b8b94c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5a2dbae-e80e-4e4b-8048-f2b075ba1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 3\n",
    "# Set up CUDA environment BEFORE importing torch\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"TRUE\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{GPU}\"  # This shrinks the GPU universe and maps cuda:0 to {GPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bbf2acc-c647-4350-a664-232b1d300b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "196f6c0e-35a7-4d28-b20b-20c4add85629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device() # This really is device {GPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b72da025-416c-46d8-8952-60b8c5f275af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import datetime\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "time = datetime.datetime.now().strftime('%H.%M')\n",
    "\n",
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MIRNA_MODEL_ROOT,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    #fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{MIRNA_MODEL_ROOT}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    #place_model_on_device=torch.device(f\"cuda:{GPU}\"),\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=12.0,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=mirna_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=mirna_tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "634cb99a-bedd-4767-b0cd-385938339397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "/home/dkarpeyev/.conda/envs/py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1725\n",
      "  Num Epochs = 12\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1296\n",
      "  Number of trainable parameters = 85919232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1296' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1296/1296 00:59, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.132821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.974031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.941169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.915771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.960500</td>\n",
       "      <td>3.918980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.960500</td>\n",
       "      <td>3.908008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.960500</td>\n",
       "      <td>3.914678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.960500</td>\n",
       "      <td>3.908233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.960500</td>\n",
       "      <td>3.916514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.591300</td>\n",
       "      <td>3.940829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.591300</td>\n",
       "      <td>3.939182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.591300</td>\n",
       "      <td>3.945644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500\n",
      "Configuration saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500/config.json\n",
      "Configuration saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500/generation_config.json\n",
      "Model weights saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000\n",
      "Configuration saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000/config.json\n",
      "Configuration saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000/generation_config.json\n",
      "Model weights saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: length, overflow_to_sample_mapping. If length, overflow_to_sample_mapping are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1296, training_loss=3.6866623207374856, metrics={'train_runtime': 59.5424, 'train_samples_per_second': 347.651, 'train_steps_per_second': 21.766, 'total_flos': 433596265344000.0, 'train_loss': 3.6866623207374856, 'epoch': 12.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7bc7b16-70e9-47af-9884-a9ef5b61b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"/mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": null,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100\n",
      "}\n",
      "\n",
      "loading weights file /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file /mnt/data/home/dkarpeyev/micron/notebooks/mirna/model=mirna/version=0/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(100, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    model = model.from_pretrained(MIRNA_MODEL_ROOT)\n",
    "except:\n",
    "    model.to(f\"cuda:0\")\n",
    "    trainer.train()\n",
    "    model.to(\"cpu\").save_pretrained(MIRNA_MODEL_ROOT, from_pt=True)\n",
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3376c-f303-4611-a7a4-4396ba2a94c0",
   "metadata": {},
   "source": [
    "### Quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa56931f-2655-40ab-8d32-ad56df98e8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 50,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "/home/dkarpeyev/.conda/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 634 ms, sys: 69.2 ms, total: 703 ms\n",
      "Wall time: 722 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'UCAGCAGGCAGCCUUCAGAGGGAAGCACUGGGGGUUUUCCUCUGGGGAAAGGAGGCUCAUAGCGGCAGGUCCAGGGCUGGUUGGCGGC'},\n",
       " {'generated_text': 'UGCUCGGUUUGAUUCCAUCUCAAUGGUCUCAAUUAAGGCACACAGAGGGAAGCCACAAUAACAGGAAAACUAGAUGCCUACC'},\n",
       " {'generated_text': 'UGAAGCUCCUGGAUUCCCUACAAAGCAACGUACUCGGGAGAAUUGUCCGGGGCAGGUGAAAAGAAAAGGCGGGGGGGAGG'},\n",
       " {'generated_text': 'AUGUUGGCCUAGAGCAAGAAAUAUUGGCAUCUAAGAAGAUCUAAAAACAGAGAACAUCUAUUACUUUGGUAUUUGAGAUAC'},\n",
       " {'generated_text': 'UCGGG'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "set_seed(42)\n",
    "generator(\"\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c254c429-c80f-43b8-90e5-31cbc3b75be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 50,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 ms, sys: 1.06 ms, total: 245 ms\n",
      "Wall time: 244 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'UCAGCAGGCAGCCUUCAGAGGGAAGCACUGGGGGUUUUCCUCUGGGGAAAGGAGGCUCAUAGCGGCAGGUCCAGGGCUGGUUGGCGGC'},\n",
       " {'generated_text': 'UGCUCGGUUUGAUUCCAUCUCAAUGGUCUCAAUUAAGGCACACAGAGGGAAGCCACAAUAACAGGAAAACUAGAUGCCUACC'},\n",
       " {'generated_text': 'UGAAGCUCCUGGAUUCCCUACAAAGCAACGUACUCGGGAGAAUUGUCCGGGGCAGGUGAAAAGAAAAGGCGGGGGGGAGG'},\n",
       " {'generated_text': 'AUGUUGGCCUAGAGCAAGAAAUAUUGGCAUCUAAGAAGAUCUAAAAACAGAGAACAUCUAUUACUUUGGUAUUUGAGAUAC'},\n",
       " {'generated_text': 'UCGGG'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "set_seed(42)\n",
    "generator(\"\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc174d42-3def-4e09-82bd-f06e13ca39f1",
   "metadata": {},
   "source": [
    "# LATENT-SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b293e42-fbde-4711-9f22-90dbd63e2b19",
   "metadata": {},
   "source": [
    "From `transformers.generation.utils.GenerationMixin.compute_transition_scores()` docstring:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "...\n",
    "\n",
    "Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "        >>> import numpy as np\n",
    "\n",
    "        >>> tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        >>> model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "        >>> tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        >>> inputs = tokenizer([\"Today is\"], return_tensors=\"pt\")\n",
    "\n",
    "        >>> # Example 1: Print the scores for each token generated with Greedy Search\n",
    "        >>> outputs = model.generate(**inputs, max_new_tokens=5, return_dict_in_generate=True, output_scores=True)\n",
    "        >>> transition_scores = model.compute_transition_scores(\n",
    "        ...     outputs.sequences, outputs.scores, normalize_logits=True\n",
    "        ... )\n",
    "        >>> input_length = inputs.input_ids.shape[1]\n",
    "        >>> generated_tokens = outputs.sequences[:, input_length:]\n",
    "        >>> for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "        ...     # | token | token string | logits | probability\n",
    "        ...     print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")\n",
    "        |   262 |  the     | -1.414 | 24.33%\n",
    "        |  1110 |  day     | -2.609 | 7.36%\n",
    "        |   618 |  when    | -2.010 | 13.40%\n",
    "        |   356 |  we      | -1.859 | 15.58%\n",
    "        |   460 |  can     | -2.508 | 8.14%\n",
    "\n",
    "        >>> # Example 2: Reconstruct the sequence scores from Beam Search\n",
    "        >>> outputs = model.generate(\n",
    "        ...     **inputs,\n",
    "        ...     max_new_tokens=5,\n",
    "        ...     num_beams=4,\n",
    "        ...     num_return_sequences=4,\n",
    "        ...     return_dict_in_generate=True,\n",
    "        ...     output_scores=True,\n",
    "        ... )\n",
    "        >>> transition_scores = model.compute_transition_scores(\n",
    "        ...     outputs.sequences, outputs.scores, outputs.beam_indices, normalize_logits=False\n",
    "        ... )\n",
    "        >>> # If you sum the generated tokens' scores and apply the length penalty, you'll get the sequence scores.\n",
    "        >>> # Tip: set `normalize_logits=True` to recompute the scores from the normalized logits.\n",
    "        >>> output_length = inputs.input_ids.shape[1] + np.sum(transition_scores.numpy() < 0, axis=1)\n",
    "        >>> length_penalty = model.generation_config.length_penalty\n",
    "        >>> reconstructed_scores = transition_scores.sum(axis=1) / (output_length**length_penalty)\n",
    "        >>> print(np.allclose(outputs.sequences_scores, reconstructed_scores))\n",
    "        True\n",
    "        ```\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da89c9-9ef1-4f9b-a9e6-6cd1a3ef5332",
   "metadata": {},
   "source": [
    "`generator(\"\", max_length=30, num_return_sequences=5)` results in this call to `GenerationMixin.generate()`:\n",
    "\n",
    "`model.generate(input_ids=None, attention_mask=None, generate_kwargs={'max_length': 30, 'num_return_sequences': 5})`\n",
    "\n",
    "We augment it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63f26060-662f-4855-9e1c-255e7edf76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RETURN_SEQUENCES = 100\n",
    "MAX_LENGTH = MIRNA_MAX_SEQUENCE_LENGTH\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c56a5394-a0fe-4f9d-af7f-ea555968c92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 50,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 659 ms, total: 3.89 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.generate(input_ids=None, \n",
    "                         attention_mask=None, \n",
    "                         return_dict_in_generate=True, \n",
    "                         output_scores=True,        # to compute perplexity/cross-entropy later\n",
    "                         output_attentions=True,    # for viz\n",
    "                         output_hidden_states=True, # for UMAP\n",
    "                         max_length=MAX_LENGTH, \n",
    "                         num_return_sequences=NUM_RETURN_SEQUENCES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70626c0b-5086-4213-8260-2aad7b6ea933",
   "metadata": {},
   "source": [
    "## SEQUENCES (HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "522a56e6-ad96-4a17-8588-c9fb81302dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UACUUGUCCGAGCACUGGACGCUUAGCCUUCUGCUUUCCACUGGAACUACUUCCUUCUGUUCGACUGGACAGUAUGGCAGAAUUUGCUCUGAAUGGUCAGGAGAUGUGGCACCUGAGCGGAAGUACCCGGACAAGUGUCAUUCGAGCCUAAGGAAUGGCUGAUGCACUGGAAAUCUCCGUGGAGGGGUUCCGUGGGAUUUGCAAAAGUGAUAAAUAUGUGUAGCGGCAGGUUUGGGAAGUGCUAGGAGGAAACAGUGAGGCUCGCUUAAGAUUCUGGGGACUCAAGCCUGAAAAUCCUUCCUGUGGAAUUCCCUCAGUGCGAGGGGCUGCCCACAGGGCAAACUGGAAGAUGCGAUAGCAGAGUGGACUCUAGAUAUGGAAGGCACUGGGAGAGCUGGGUAGACCCCCAGAUGCAGGGCAAGCAGCUGCUGCACGCAUGCUGAGGAAUGCAAAUGCACCACACAUAAGUGUUAGGGGCUUCAACCGAUGACUCCGGCAGGGCC',\n",
       " 'UUUGGGAGGAGUCUGGAAGCCUAUGGCUGUGCAAAAGCCGCUUUAGGUUGCCCACUUGUGGAGAGAGGUUCAGUAGCCAUUGCGCUGGCUACAGCCCCUGGGCCCUGGGGAAUUGGGGCUGGGCAAUGCCUGGUUUUGGGCGGCAGAGUGGCAGAGGGUGGCAGGAAAUGUGGCGAGAAGGGCCCAGGGUUGACCGACGGGCGCGCCGUGCAAUCUCUCGUACCAAGCCCAGGGUCUAUGCCCUGCUGGGCAGGGAAGAAGAUAGAAACCGACUACAGACCUCCCCUUCCACAUCUCUGCGUGGGGAGUGUUGGGCGAGCAGGCCCUGCCCAGCGACAGUGCCUCUCGGAGCCCCAGCCUACCCCAGUUCUCAGGAUUCCUCGACCCCCUGACCUCGAGGAGGGCCCACCUCAUCAGACUCAAGGGCUGGGCUCAGCUGGGUUCAGCGUGCACCCUCCCCUGAACCGAGCCUUGCCAGGGCUGCCUGGCUGGAAGAAGCGGGCGCUGAACGUGGAGAUGCAAACUAGAAGG',\n",
       " 'AGCCAGAAGCCAACAUGGGGGAUGGAGGCAUAUUGGAGCUGUUGCUCUGCCCUACUGCCACCCCAGCUGGCUUUUCCAAUUGCCGUUCCCUUGGAGCCCCGAUGGCUGGACUACAGGGAACCUGUUCCCUGUGGCUGAAGUAAAUGACAGUGGCUCAGGGCAGAUGGCAGUGUGGCUUCUGGGUUGUCCGGGACUCAGGGCUGGCAGGAUUUGAGCCCUUUGAGGUUAGGAAGGUGGCUGGACCUCGGAAGCUCCCCAGCAGCCCCGAGCGAGGUUGGAAAUGCCUGAUGGCUUUUUGUCUAGGAGGGCAUUGUCCAGAUGGAAGGGGCUGAUGGAUGUGGCUUCCAGUAGUCCGAGGAGCUGUAGCUGAUGACGGAGGGGCUGGGCCGUGUUGGGGAGAAGGCUCAGUGAUGUGGGGCAGGGGUGGGAACCGAGCCGCUGAGUGGGGGGGCCAGGGCGCUGGGGCAGCAGGACGCUGGGCAGGGCUCAGCCUGAUGGUAGGGCGUGGCAUGCCAGCCCAGCCUGGCUGCAAAGGCUAGAAGGGG',\n",
       " 'UCUAAUCCAAAUAUCAUUCACUCUAUUGGAUGGGACUGGUUCCAGAAGGCUGCAAAGGGAGUCCUUUGGUGGGACAAACCAGAUGGAAAGGGUGCGAUGAGAGCCCUGCCGCCUCCAUGACACCUGGUGUGGUUCCUGAUGGCUGGAAUAAGCUGAAGAAGCACUGGACUGAAGAUGCGUAGUUUAGGUCAGGUUGCCCAGCUCAAAACAGGGCUUCCACUUCCGAGCAGAUCUGAGUUUGCAGGGCCGUUUAAAGGGAGCCAUGAGUGAAAGGACUCUCUAAGCUGAGGGAGAAAGCGCUUCCACUGACAUGAGCGAGAAAUGGGAGGUUAGGACUUGGUGCAAAUGCUGUCUGUUGGGGCUGCCUGCCCAGCGACCCUGUGAGGCCUUGGACUUGGUUACGAGAAAGUUGGCAGAGGUAGAAAGCCGCCUGUCUGACCCUUCCUGGGCUGCAAAUCUGGGCAUGUCCAGAGGGCCUGGCAGGGAGUAAGGUCUCAUGACGGGUAGAAGGAAUGUGAUCCGUUCUUCC',\n",
       " 'AAGGCCAUCAAUAAGGUGUGAAGGCGAGACACCAAGAGGUAGCCAACAGGUUGUCCGUGGGCCACGCGUGCUUGACGCUGCUUCCAAUGGGUUGGGGCUGGGCGAGGGGCACCUCUGGGGAGGGGGCAGGGGUCGCGCCGCUAUUAGCCUGGUUCCUGGGGGCCAUGCUCGCUGGGGGGAGGGUUGUGCAAAUCCAUUCAUCCGAGGAGGGGCCCUGAAGGCAGGGGCCCAGCUGGCUGGAGGCAGGGGUCGGCCGGGGCUCGUCGUGCACAGCCGCCUCCGGCUGGGCCAGGGCAGGGUCACGCUUCCCCCGGAAGUGGGGCAUCGGGUGCCGGCCGCCCGCGGGUGCCGGAGCCCCAGCCGGGGCCCAGCGGCGGCGCGAGGUCUCGCGGGAAGGGGAAAUCGGGAGCCCCCGUGUCGGCCCGUGCGGCCCGCCCGGUAUGGCUUCCCCCGUCCCGCGCGUGCCGCCCGGCCUUCGGGUGGGGGCUCGGGCCGCUCAAGGGGCUGUUGGAGCCCGCCCUCG']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_SAMPLES = 5\n",
    "tokenizer.batch_decode(outputs.sequences[:N_SAMPLES,:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2caf12-9691-4b07-b1e4-7a4027a9a6fc",
   "metadata": {},
   "source": [
    "## LATENTS (UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d9ec24a-b00f-402b-8480-e14b691f89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aa62c0f-7d96-4ce6-921d-050685344dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.hidden_states) # one per sequence element, except the last one -- the model is not evaluated on it as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "997de997-9583-4645-b9b1-660835b543bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.hidden_states[0]) # one per layer: 12 GPT2Blocks followd by a LayerNorm for a total of 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ed06bc3-fbb5-4c9d-b9c5-2c97cb980d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 768])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[0][-1].shape # last layer is the logits -- the activations of the final LayerNorm following the 12 transformer blocks\n",
    "# shape: [NUM_RETURN_SEQUENCES, 1, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d7c5bec-1b25-41aa-9de4-fe7ec0c49e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_latents: concat the activations from the last hidden layer for all sequence elements\n",
    "# H is the last activation of shape [N, 1, D]\n",
    "long_latents_list = [h.reshape(h.shape[0], h.shape[-1]) for h in [H[-1] for H in outputs.hidden_states]]\n",
    "long_latents = torch.cat(long_latents_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c68caad-94e1-4711-8b55-7cc4f3733dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 137472])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ab10006-ef5f-43ff-a365-8a119e660b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_latents: take the last hidden layer activation for the last element of each sequence\n",
    "_ = outputs.hidden_states[-1][-1]\n",
    "short_latents = _.reshape((_.shape[0], _.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42841f23-c46b-4464-8e1f-dc963156d43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 768])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_latents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1f1c5-c18b-4747-866d-023421afd16c",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6bf04e26-76ef-4e7f-b26a-a38be78e14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "430543dd-c709-4b45-9970-45f139df8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='poster', rc={'figure.figsize':(1000,500)})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4d30de2-6502-4ad4-85a0-5fd1ac8f2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41efa952-81de-4672-bde3-2ebaf231ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 221 ms, total: 3min 10s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lu = fit.fit_transform(long_latents.cpu().detach().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1c32e14-3eba-489f-81fe-b7a0a74a62c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9b53dc2-97ef-4c7b-a289-885e2f1bd53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efe14e08a30>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=lu[:,0], y=lu[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "835ed2e5-109b-46ff-8d9c-b50451380f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 133 ms, total: 2min 58s\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "su = fit.fit_transform(short_latents.cpu().detach().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f23f42de-a9dc-4e55-bf4d-481583144383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "02fa1226-8892-450f-ae6f-081a75427d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efe14e178b0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=su[:,0], y=su[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5773c6a-0110-47b4-9c44-73c8bd4a191c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
